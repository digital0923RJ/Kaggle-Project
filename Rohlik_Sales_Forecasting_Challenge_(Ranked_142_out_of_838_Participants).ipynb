{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMrIOFsgruJ6zGs3pUZDoMj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/digital0923RJ/Kaggle-Project/blob/main/Rohlik_Sales_Forecasting_Challenge_(Ranked_142_out_of_838_Participants).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rohlik Sales Forecasting Challenge**\n",
        "\n",
        "### **About Rohlik Group**\n",
        "Rohlik Group, a leading European e-grocery innovator, is revolutionizing the food retail industry. We operate across **11 warehouses** in **Czech Republic, Germany, Austria, Hungary, and Romania**.\n",
        "\n",
        "### **Goal**\n",
        "The challenge focuses on **predicting the sales** of each selected warehouse inventory for the next **14 days** using **historical sales data**.\n",
        "\n",
        "### **Evaluation Metric**\n",
        "Submissions are evaluated using **Weighted Mean Absolute Error (WMAE)** between the predicted sales and the actual sales. Weights for the test evaluation are provided in the **Data section**.\n",
        "\n",
        "---\n",
        "\n",
        "## **My Approach**\n",
        "\n",
        "### **1️⃣ Addressing Residuals in Time-Series Forecasting**\n",
        "- Since this is a **time-series problem**, I focused on **lag features** and **residual analysis**.\n",
        "- Sorted the dataset by **warehouse names, dates, and sales** to detect trends.\n",
        "- Observed that **residuals were increasing over time**, requiring further investigation.\n",
        "- To address this, I **filled in missing dates, holidays**, and introduced **lagging features**.\n",
        "\n",
        "### **2️⃣ Skewed Distribution and Log Transformation**\n",
        "- The initial model’s **prediction distribution was highly skewed**, making accurate prediction difficult.\n",
        "- Applied **log transformation** to make the target variable follow a **normal distribution**, which stabilized the model’s predictions.\n",
        "- Removed **negative residual values**, as they negatively impacted **WMAE scoring**.\n",
        "\n",
        "### **3️⃣ Hyperparameter Optimization Using Optuna**\n",
        "- Used **Optuna** to tune key hyperparameters such as:\n",
        "  - **Learning rate**\n",
        "  - **Number of leaves**\n",
        "  - **Max depth**\n",
        "  - **Regularization (L1, L2)**\n",
        "- The optimization was based on **TimeSeriesSplit cross-validation** and evaluated using **Weighted MAE (WMAE)**.\n",
        "\n",
        "### **4️⃣ Model Training and Submission**\n",
        "- Trained a **LightGBM (LGBM) model** using the best hyperparameters.\n",
        "- Applied **inverse log transformation** to convert predictions back to the original scale.\n",
        "- Ensured **no negative values** in the final predictions before submission.\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "MJBfGBiW3lmV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "METrGgniGJqb",
        "outputId": "3d2e4ff3-4e80-4194-e02a-b59c79f712ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1-Wiya6GSnF",
        "outputId": "664b148a-69db-4395-b376-5c9beaf9564d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/포트폴리오/rohlik-sales-forecasting-challenge-v2/\"\n",
        "train = pd.read_csv(f'{base_path}sales_train.csv', parse_dates=['date'])\n",
        "inventory = pd.read_csv(f'{base_path}inventory.csv')\n",
        "test = pd.read_csv(f'{base_path}sales_test.csv', parse_dates=['date'])\n",
        "calendar = pd.read_csv(f'{base_path}calendar.csv', parse_dates=['date'])\n",
        "test_weights = pd.read_csv(f'{base_path}test_weights.csv')\n",
        "calendar_enriched = pd.read_csv(f'{base_path}calendar_enriched.csv')"
      ],
      "metadata": {
        "id": "59p5X9aoGUkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train[['total_orders', 'sales']] = train[['total_orders', 'sales']].fillna(train[['total_orders', 'sales']].mean(numeric_only=True))"
      ],
      "metadata": {
        "id": "zG83Y1n4KWV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_train_by_test_unique_id(sales_train, sales_test, unique_id_col='unique_id'):\n",
        "\n",
        "    # get the unique_id from test dataset\n",
        "    test_unique_ids = set(test[unique_id_col].unique())\n",
        "\n",
        "    # leave only unique_id from test data from the train data\n",
        "    filtered_train_df = train[train[unique_id_col].isin(test_unique_ids)].copy()\n",
        "\n",
        "    # Before and After of filtering of 'unique_id'\n",
        "    train_unique_count_before = train[unique_id_col].nunique()\n",
        "    train_unique_count_after = filtered_train_df[unique_id_col].nunique()\n",
        "    test_unique_count = test[unique_id_col].nunique()\n",
        "\n",
        "    print(f\"🔹 Before filtering Train_data Unique ID #N : {train_unique_count_before}\")\n",
        "    print(f\"🔹 After filtering Train_data Unique ID #N: {train_unique_count_after}\")\n",
        "    print(f\"🔹 Test data Unique ID #N: {test_unique_count}\")\n",
        "\n",
        "    return filtered_train_df\n",
        "\n",
        "# filtering\n",
        "filtered_sales_train = filter_train_by_test_unique_id(train, test, unique_id_col='unique_id')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkY_i0dbKaln",
        "outputId": "88c74747-b5f0-49be-cc9a-6697c4306f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 필터링 전 Train 데이터 Unique ID 개수: 5390\n",
            "🔹 필터링 후 Train 데이터 Unique ID 개수: 3625\n",
            "🔹 Test 데이터 Unique ID 개수: 3625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = filtered_sales_train"
      ],
      "metadata": {
        "id": "Iz4kG9waKYXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure 'date' columns are of datetime type before merging\n",
        "train['date'] = pd.to_datetime(train['date'])\n",
        "calendar_enriched['date'] = pd.to_datetime(calendar_enriched['date'])\n",
        "\n",
        "# Now perform the merge\n",
        "train = train.merge(calendar_enriched, on=['warehouse', 'date'], how='left')\n",
        "test = test.merge(calendar_enriched, on=['warehouse', 'date'], how='left')"
      ],
      "metadata": {
        "id": "9hvr-9R6KdXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=train.merge(test_weights,on='unique_id',how='left')"
      ],
      "metadata": {
        "id": "0kWHSbPZLjVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=train.merge(inventory,on=['warehouse','unique_id'],how='left')\n",
        "test=test.merge(inventory,on=['warehouse','unique_id'],how='left')\n",
        "\n",
        "train=train[train['date']>='2021-06-01']\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "FU_f_wTbLjz5",
        "outputId": "802f0bee-9778-4da5-f607-256d224e60c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unique_id       date   warehouse  total_orders  sales  sell_price_main  \\\n",
              "0       4845 2024-03-10  Budapest_1        6436.0  16.34           646.26   \n",
              "2       4845 2021-12-20  Budapest_1        6507.0  34.55           455.96   \n",
              "3       4845 2023-04-29  Budapest_1        5463.0  34.52           646.26   \n",
              "4       4845 2022-04-01  Budapest_1        5997.0  35.92           486.41   \n",
              "5       4845 2024-03-02  Budapest_1        6760.0  27.26           646.26   \n",
              "\n",
              "   availability  type_0_discount  type_1_discount  type_2_discount  ...  \\\n",
              "0          1.00          0.00000              0.0              0.0  ...   \n",
              "2          1.00          0.00000              0.0              0.0  ...   \n",
              "3          0.96          0.20024              0.0              0.0  ...   \n",
              "4          1.00          0.00000              0.0              0.0  ...   \n",
              "5          1.00          0.00000              0.0              0.0  ...   \n",
              "\n",
              "   date_second_closed_day  date_day_after_two_closed_days  date_year  \\\n",
              "0                       0                               0       2024   \n",
              "2                       0                               0       2021   \n",
              "3                       0                               0       2023   \n",
              "4                       0                               0       2022   \n",
              "5                       0                               0       2024   \n",
              "\n",
              "     weight product_unique_id          name  L1_category_name_en  \\\n",
              "0  1.925596              2375  Croissant_35               Bakery   \n",
              "2  1.925596              2375  Croissant_35               Bakery   \n",
              "3  1.925596              2375  Croissant_35               Bakery   \n",
              "4  1.925596              2375  Croissant_35               Bakery   \n",
              "5  1.925596              2375  Croissant_35               Bakery   \n",
              "\n",
              "   L2_category_name_en  L3_category_name_en  L4_category_name_en  \n",
              "0         Bakery_L2_18         Bakery_L3_83          Bakery_L4_1  \n",
              "2         Bakery_L2_18         Bakery_L3_83          Bakery_L4_1  \n",
              "3         Bakery_L2_18         Bakery_L3_83          Bakery_L4_1  \n",
              "4         Bakery_L2_18         Bakery_L3_83          Bakery_L4_1  \n",
              "5         Bakery_L2_18         Bakery_L3_83          Bakery_L4_1  \n",
              "\n",
              "[5 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3007be75-9d2f-4206-8bdd-069481b40720\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>date</th>\n",
              "      <th>warehouse</th>\n",
              "      <th>total_orders</th>\n",
              "      <th>sales</th>\n",
              "      <th>sell_price_main</th>\n",
              "      <th>availability</th>\n",
              "      <th>type_0_discount</th>\n",
              "      <th>type_1_discount</th>\n",
              "      <th>type_2_discount</th>\n",
              "      <th>...</th>\n",
              "      <th>date_second_closed_day</th>\n",
              "      <th>date_day_after_two_closed_days</th>\n",
              "      <th>date_year</th>\n",
              "      <th>weight</th>\n",
              "      <th>product_unique_id</th>\n",
              "      <th>name</th>\n",
              "      <th>L1_category_name_en</th>\n",
              "      <th>L2_category_name_en</th>\n",
              "      <th>L3_category_name_en</th>\n",
              "      <th>L4_category_name_en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4845</td>\n",
              "      <td>2024-03-10</td>\n",
              "      <td>Budapest_1</td>\n",
              "      <td>6436.0</td>\n",
              "      <td>16.34</td>\n",
              "      <td>646.26</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2024</td>\n",
              "      <td>1.925596</td>\n",
              "      <td>2375</td>\n",
              "      <td>Croissant_35</td>\n",
              "      <td>Bakery</td>\n",
              "      <td>Bakery_L2_18</td>\n",
              "      <td>Bakery_L3_83</td>\n",
              "      <td>Bakery_L4_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4845</td>\n",
              "      <td>2021-12-20</td>\n",
              "      <td>Budapest_1</td>\n",
              "      <td>6507.0</td>\n",
              "      <td>34.55</td>\n",
              "      <td>455.96</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2021</td>\n",
              "      <td>1.925596</td>\n",
              "      <td>2375</td>\n",
              "      <td>Croissant_35</td>\n",
              "      <td>Bakery</td>\n",
              "      <td>Bakery_L2_18</td>\n",
              "      <td>Bakery_L3_83</td>\n",
              "      <td>Bakery_L4_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4845</td>\n",
              "      <td>2023-04-29</td>\n",
              "      <td>Budapest_1</td>\n",
              "      <td>5463.0</td>\n",
              "      <td>34.52</td>\n",
              "      <td>646.26</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.20024</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2023</td>\n",
              "      <td>1.925596</td>\n",
              "      <td>2375</td>\n",
              "      <td>Croissant_35</td>\n",
              "      <td>Bakery</td>\n",
              "      <td>Bakery_L2_18</td>\n",
              "      <td>Bakery_L3_83</td>\n",
              "      <td>Bakery_L4_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4845</td>\n",
              "      <td>2022-04-01</td>\n",
              "      <td>Budapest_1</td>\n",
              "      <td>5997.0</td>\n",
              "      <td>35.92</td>\n",
              "      <td>486.41</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2022</td>\n",
              "      <td>1.925596</td>\n",
              "      <td>2375</td>\n",
              "      <td>Croissant_35</td>\n",
              "      <td>Bakery</td>\n",
              "      <td>Bakery_L2_18</td>\n",
              "      <td>Bakery_L3_83</td>\n",
              "      <td>Bakery_L4_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4845</td>\n",
              "      <td>2024-03-02</td>\n",
              "      <td>Budapest_1</td>\n",
              "      <td>6760.0</td>\n",
              "      <td>27.26</td>\n",
              "      <td>646.26</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2024</td>\n",
              "      <td>1.925596</td>\n",
              "      <td>2375</td>\n",
              "      <td>Croissant_35</td>\n",
              "      <td>Bakery</td>\n",
              "      <td>Bakery_L2_18</td>\n",
              "      <td>Bakery_L3_83</td>\n",
              "      <td>Bakery_L4_1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3007be75-9d2f-4206-8bdd-069481b40720')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3007be75-9d2f-4206-8bdd-069481b40720 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3007be75-9d2f-4206-8bdd-069481b40720');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-23b4ed24-95ab-4940-8a19-69dc32b2f9d0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23b4ed24-95ab-4940-8a19-69dc32b2f9d0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-23b4ed24-95ab-4940-8a19-69dc32b2f9d0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop(columns=['availability'])\n",
        "train.dropna(subset=['sales'], inplace=True)"
      ],
      "metadata": {
        "id": "A0YGD1KgLsR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['sales'] = 0\n",
        "df = pd.concat([train, test], ignore_index=True).sort_values('date')"
      ],
      "metadata": {
        "id": "1aTAh9v3LvWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PERIODS = [14, 20, 28, 35, 90, 180, 270]\n",
        "def add_date_features(df):\n",
        "    df['date_month'] = df['date'].dt.month\n",
        "    df['date_day'] = df['date'].dt.day\n",
        "    df['date_weekofyear'] = df['date'].dt.isocalendar().week\n",
        "    df['date_weekday'] = df['date'].dt.weekday\n",
        "    df['date_year'] = df['date'].dt.dayofyear\n",
        "    df['date_year_sin'] = np.sin((df['date_year'] - df['date_year'].min()) / (df['date_year'].max() - df['date_year'].min()) * 2 * np.pi)\n",
        "    df['date_year_sin'] = np.sin(df['date_year'] / 1 * 2 * np.pi)\n",
        "    df['date_month_sin'] = np.sin(df['date_month'] / 12 * 2 * np.pi)\n",
        "    return df\n",
        "\n",
        "def add_product_category(df):\n",
        "    df['category'] = df['name'].str.split('_',expand=True)[0]\n",
        "    return df\n",
        "\n",
        "def add_lagged_product_sales(df):\n",
        "    for shift in PERIODS:\n",
        "        df[f'product_sales_{shift}']=df.groupby(['warehouse','name'])['sales'].shift(periods=shift)\n",
        "    return df\n",
        "\n",
        "df = add_date_features(df)\n",
        "df = add_product_category(df)\n",
        "df = add_lagged_product_sales(df)"
      ],
      "metadata": {
        "id": "VyjDT5VyLvUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['year'] = df['date'].dt.year\n",
        "df['month'] = df['date'].dt.month\n",
        "df['day'] = df['date'].dt.day\n",
        "df['weekday'] = df['date'].dt.weekday\n",
        "df['dayofweek'] = df['date'].dt.dayofweek\n",
        "df['weekofyear'] = df['date'].dt.isocalendar().week\n",
        "df['dayofyear'] = df['date'].dt.dayofyear\n",
        "df['is_month_start'] = df['date'].dt.is_month_start\n",
        "df['is_month_end'] = df['date'].dt.is_month_end\n",
        "df['quarter'] = df['date'].dt.quarter\n",
        "df[\"total_dic\"]=df['type_0_discount']+df['type_0_discount']+df['type_1_discount']+df['type_2_discount']+df['type_3_discount']+df['type_4_discount']+df['type_5_discount']+df['type_6_discount']\n",
        "df['total_orders_']=df['total_orders']/df['sell_price_main']\n",
        "df['total_orders_dic']=df['total_orders_']/df[\"total_dic\"]\n",
        "df['total_orders_sell_price_main']=df['sell_price_main']/df[\"total_dic\"]\n",
        "for i in range(7):\n",
        "    df[f'total_orders{i}']=df[f'type_{i}_discount']/df[\"total_orders\"]\n",
        "    df[f'total_orders_sell_price_main_{i}']=df[f'type_{i}_discount']/df[\"total_orders_sell_price_main\"]\n",
        "    df[f'sell_price_main{i}']=df[f'type_{i}_discount']/df[\"sell_price_main\"]\n",
        "    df[f'sell_price_main_x_{i}']=df[f'type_{i}_discount']/(df[\"sell_price_main\"]*df[\"total_orders\"])\n",
        "    df[f'total_orders_dic{i}']=df[f'type_{i}_discount']/df[\"total_orders_dic\"]\n",
        "\n",
        "    df[f'_total_orders{i}']=df[f'type_{i}_discount']*df[\"total_orders\"]\n",
        "    df[f'_total_orders_sell_price_main_{i}']=df[f'type_{i}_discount']*df[\"total_orders_sell_price_main\"]\n",
        "    df[f'_sell_price_main{i}']=df[f'type_{i}_discount']*df[\"sell_price_main\"]\n",
        "    df[f'_total_orders_dic{i}']=df[f'type_{i}_discount']*df[\"total_orders_dic\"]\n",
        "\n",
        "df.fillna(0, inplace=True)\n",
        "\n",
        "categorical_columns=['unique_id']+list(df.select_dtypes(\"object\").columns)\n",
        "\n",
        "for col in categorical_columns:\n",
        "    df[col] = df[col].astype('category')"
      ],
      "metadata": {
        "id": "MSSMkdzULuxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_start_date  = '2020-08-01'\n",
        "train_end_date  = '2024-06-02'\n",
        "test_start_date = '2024-03-18'\n",
        "test_end_date = '2024-06-01'\n",
        "train_df = df[(df['date'] >= train_start_date) & (df['date'] <= train_end_date)]\n",
        "test_df  = df[(df['date'] >  train_end_date)]\n",
        "train_data = df[(df['date'] < train_end_date)]\n",
        "test_data = df[(df['date'] >= test_start_date)]"
      ],
      "metadata": {
        "id": "QNvxlN7bLuDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape, test_df.shape, train_data.shape, test_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spibdwyXMa4Y",
        "outputId": "4ea2375f-9982-48c8-96ed-b8f9ee2086c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2938869, 122), (47021, 122), (2935551, 122), (295084, 122))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['sales', 'date','weight'], axis=1)\n",
        "y = np.log1p(df['sales'])\n",
        "train_weights = train_data['weight']"
      ],
      "metadata": {
        "id": "OIBGTljWMqWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data.drop(['sales', 'date', 'weight'], axis=1)\n",
        "y_train = np.log1p(train_data['sales'])\n",
        "train_weights = train_data['weight']\n",
        "cols=X.select_dtypes([\"int\",\"float\"]).columns"
      ],
      "metadata": {
        "id": "zYU1V9_LMmRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, train_weights.shape"
      ],
      "metadata": {
        "id": "wWdgXuaaNANI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080d16ed-df03-48f7-f77c-d1f68c81f786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2935551, 119), (2935551,), (2935551,))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "99DWbSSsOkjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3594012d-3cc7-4b67-b1e9-be42962d9897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.37)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "import numpy as np\n",
        "\n",
        "sc = RobustScaler()\n",
        "\n",
        "for col in cols:\n",
        "    df[col].replace([np.inf, -np.inf], df[col].min(), inplace=True)\n",
        "    df[col].fillna(X_train[col].mean(), inplace=True)\n",
        "    # Transform the entire column in 'df' instead of just 'X_train'\n",
        "    df[col] = sc.fit_transform(df[[col]])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "pObsQukSNon5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_feature_indices = [X.columns.get_loc(col) for col in categorical_columns if col in X.columns]"
      ],
      "metadata": {
        "id": "5-ltnasqN4bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import log_evaluation, early_stopping"
      ],
      "metadata": {
        "id": "9LqEp0XDN5RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data.drop(['sales', 'date', 'weight'], axis=1)\n",
        "y_train = np.log1p(train_data['sales'])\n",
        "train_weights = train_data['weight']\n",
        "\n",
        "X_test = test_data.drop(['sales', 'date', 'weight'], axis=1)\n",
        "y_test = np.log1p(test_data['sales'])\n",
        "\n",
        "test_weights = test_data['weight']"
      ],
      "metadata": {
        "id": "ZiUJO4UHHk5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols=X.select_dtypes([\"int\",\"float\"]).columns"
      ],
      "metadata": {
        "id": "hItTj6DHHwVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Optuna 최적화 함수: LightGBM 모델의 하이퍼파라미터를 튜닝.\n",
        "    \"\"\"\n",
        "    # Hyperparameter\n",
        "    params = {\n",
        "        'objective': 'regression',\n",
        "        'metric': 'mae',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.1),\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n",
        "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
        "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
        "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n",
        "        'num_boost_round': trial.suggest_int('num_boost_round', 500, 5000),\n",
        "        'verbose': -1\n",
        "    }\n",
        "\n",
        "    # LightGBM dataset\n",
        "    train_dataset = lgb.Dataset(X_train, label=y_train,\n",
        "                                categorical_feature=categorical_feature_indices,\n",
        "                                weight=train_weights)\n",
        "    valid_dataset = lgb.Dataset(X_test, label=y_test,\n",
        "                                categorical_feature=categorical_feature_indices,\n",
        "                                weight=test_weights,\n",
        "                                reference=train_dataset)\n",
        "\n",
        "    # model training\n",
        "    model = lgb.train(params, train_dataset,\n",
        "                      num_boost_round=params['num_boost_round'],\n",
        "                      valid_sets=[valid_dataset])\n",
        "\n",
        "\n",
        "    # model prediction\n",
        "    y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
        "\n",
        "    # Reverse transformation from log\n",
        "    y_test_original = np.expm1(y_test)\n",
        "    y_pred_original = np.expm1(y_pred)\n",
        "\n",
        "    # Weighted MAE\n",
        "    weighted_mae = np.sum(test_weights * np.abs(y_test_original - y_pred_original)) / np.sum(test_weights)\n",
        "\n",
        "    return weighted_mae\n",
        "\n",
        "# Optuna implementation\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "print(study.best_trial.params)"
      ],
      "metadata": {
        "id": "Kdqrkr5oPNK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = {\n",
        "    'learning_rate': 0.07197210595947787,\n",
        "    'num_leaves': 123,\n",
        "    'max_depth': 15,\n",
        "    'min_child_samples': 30,\n",
        "    'subsample': 0.8486600816122877,\n",
        "    'colsample_bytree': 0.9205837051511344,\n",
        "    'reg_alpha': 1.8968996438676256e-05,\n",
        "    'reg_lambda': 0.00026096880620833136,\n",
        "    'num_boost_round': 2697\n",
        "}"
      ],
      "metadata": {
        "id": "z-Ie74HtzFZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub = test_df.copy()\n",
        "final_train_dataset = lgb.Dataset(X, label=y,\n",
        "                                  categorical_feature=categorical_feature_indices,\n",
        "                                  weight=df['weight'])"
      ],
      "metadata": {
        "id": "bFh1tznTGetV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-yyfvUSOAOO",
        "outputId": "2473f33c-be90-4c6f-9a7c-5ab618cffa94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['unique_id', 'date', 'warehouse', 'total_orders', 'sales',\n",
              "       'sell_price_main', 'type_0_discount', 'type_1_discount',\n",
              "       'type_2_discount', 'type_3_discount',\n",
              "       ...\n",
              "       '_total_orders_dic5', 'total_orders6', 'total_orders_sell_price_main_6',\n",
              "       'sell_price_main6', 'sell_price_main_x_6', 'total_orders_dic6',\n",
              "       '_total_orders6', '_total_orders_sell_price_main_6',\n",
              "       '_sell_price_main6', '_total_orders_dic6'],\n",
              "      dtype='object', length=122)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = lgb.train(best_params,\n",
        "                        train_set=final_train_dataset)\n",
        "\n",
        "# Drop 'date' and 'weight' columns from test_df before prediction\n",
        "test_df_processed = test_df.drop(['sales', 'date', 'weight'], axis=1)\n",
        "final_y_pred = final_model.predict(test_df_processed)\n",
        "sub['sales_hat'] = np.expm1(final_y_pred)\n",
        "sub['id']= sub['unique_id'].astype(str) + \"_\" + sub['date'].astype(str)\n",
        "sub[['id','sales_hat']].to_csv(\"submission.csv\",index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itTigSpKGeZK",
        "outputId": "4fed5ff3-3285-48f1-a095-4c89a3354a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: learning_rates\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Unknown parameter: learning_rates\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.605215 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 21959\n",
            "[LightGBM] [Info] Number of data points in the train set: 2985890, number of used features: 109\n",
            "[LightGBM] [Info] Start training from score 3.552977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bFUbz16LqQQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub['sales_hat'] = sub['sales_hat'].clip(lower=0)\n",
        "sub[['id','sales_hat']].to_csv(\"submissio_sss1.csv\", index=False)"
      ],
      "metadata": {
        "id": "buH5yxevTFTQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}